{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2387d51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\gruhi\\anaconda3\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\gruhi\\anaconda3\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in c:\\users\\gruhi\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\gruhi\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\gruhi\\anaconda3\\lib\\site-packages (1.8.2.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\gruhi\\anaconda3\\lib\\site-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gruhi\\anaconda3\\lib\\site-packages (from wordcloud) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\gruhi\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gruhi\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gruhi\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gruhi\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gruhi\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gruhi\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\gruhi\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gruhi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gruhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gruhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "#import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.feature_extraction.text as text\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import warnings\n",
    "!pip install contractions\n",
    "import contractions\n",
    "from collections import Counter\n",
    "!pip install wordcloud\n",
    "from wordcloud import WordCloud\n",
    "from sklearn. preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "import gensim\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c265950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('data.json',lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee49b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['U.S. NEWS', 'COMEDY', 'PARENTING', 'WORLD NEWS', 'CULTURE & ARTS',\n",
       "       'TECH', 'SPORTS', 'ENTERTAINMENT', 'POLITICS', 'WEIRD NEWS',\n",
       "       'ENVIRONMENT', 'EDUCATION', 'CRIME', 'SCIENCE', 'WELLNESS',\n",
       "       'BUSINESS', 'STYLE & BEAUTY', 'FOOD & DRINK', 'MEDIA',\n",
       "       'QUEER VOICES', 'HOME & LIVING', 'WOMEN', 'BLACK VOICES', 'TRAVEL',\n",
       "       'MONEY', 'RELIGION', 'LATINO VOICES', 'IMPACT', 'WEDDINGS',\n",
       "       'COLLEGE', 'PARENTS', 'ARTS & CULTURE', 'STYLE', 'GREEN', 'TASTE',\n",
       "       'HEALTHY LIVING', 'THE WORLDPOST', 'GOOD NEWS', 'WORLDPOST',\n",
       "       'FIFTY', 'ARTS', 'DIVORCE'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f4f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mappings = {tuple(['U.S. NEWS', 'WORLD NEWS',  'GOOD NEWS' , 'THE WORLDPOST','WORLDPOST']): 'NEWS',\n",
    "                  tuple(['CULTURE & ARTS', 'TRAVEL','ARTS & CULTURE','ARTS']): 'TRAVEL AND ARTS',\n",
    "                                                  tuple(['WELLNESS','STYLE & BEAUTY','HOME & LIVING','HEALTHY LIVING','STYLE']): 'LIFESTYLE',\n",
    "                                                 tuple(['TASTE','FOOD & DRINK']): 'FOOD',\n",
    "                                                  tuple(['QUEER VOICES', 'BLACK VOICES','LATINO VOICES','WOMEN']): 'DIVERSITY',\n",
    "                                                  tuple(['COMEDY','SPORTS','ENTERTAINMENT','WEIRD NEWS']): 'ENTERTAINMENT',\n",
    "                                                  tuple(['BUSINESS','MONEY']): 'BUSINESS',\n",
    "                                                  tuple(['COLLEGE','PARENTING','EDUCATION','PARENTS']): 'PARENTING AND EDUCATION',\n",
    "                                                  tuple(['CRIME','FIFTY','IMPACT','WEDDINGS','DIVORCE','RELIGION']): 'MISCELLANEOUS',\n",
    "                                                tuple(['POLITICS','MEDIA']): 'POLITICS',\n",
    "                                                 tuple(['ENVIRONMENT','GREEN']): 'ENVIRONMENT',\n",
    "                                                 tuple(['TECH','SCIENCE']): 'TECHNOLOGY'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6230f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mapping_dict = {}\n",
    "for key, value in new_mappings.items():\n",
    "    for one_key in key:\n",
    "        new_mapping_dict[one_key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0de61efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>new_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COMEDY</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PARENTING</td>\n",
       "      <td>PARENTING AND EDUCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209522</th>\n",
       "      <td>TECH</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209523</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209524</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209525</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209526</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209527 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         category             new_category\n",
       "0       U.S. NEWS                     NEWS\n",
       "1       U.S. NEWS                     NEWS\n",
       "2          COMEDY            ENTERTAINMENT\n",
       "3       PARENTING  PARENTING AND EDUCATION\n",
       "4       U.S. NEWS                     NEWS\n",
       "...           ...                      ...\n",
       "209522       TECH               TECHNOLOGY\n",
       "209523     SPORTS            ENTERTAINMENT\n",
       "209524     SPORTS            ENTERTAINMENT\n",
       "209525     SPORTS            ENTERTAINMENT\n",
       "209526     SPORTS            ENTERTAINMENT\n",
       "\n",
       "[209527 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['new_category'] = data['category'].replace(new_mapping_dict)\n",
    "data.loc[:,['category','new_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2699423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEWS', 'ENTERTAINMENT', 'PARENTING AND EDUCATION',\n",
       "       'TRAVEL AND ARTS', 'TECHNOLOGY', 'POLITICS', 'ENVIRONMENT',\n",
       "       'MISCELLANEOUS', 'LIFESTYLE', 'BUSINESS', 'FOOD', 'DIVERSITY'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.new_category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12bcbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeab7c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['headline', 'short_description'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9f83ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209038, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e2f3078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d95d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da7c736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['all_words'] = df['headline']+\" \"+df['short_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f8e7486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Over 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters Health experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['all_words'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd03b72",
   "metadata": {},
   "source": [
    "# data Cleaning / preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47754287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(combined_words):\n",
    "    expanded_words = []   \n",
    "    for word in combined_words.split():\n",
    "        expanded_words.append(contractions.fix(word))  \n",
    "    expanded_text = ' '.join(expanded_words)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11876df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27905ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(x):\n",
    "    lst = [i for i in x.split() if not i in stop_words]\n",
    "    data = ' '.join(lst)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa6de2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    data = str(data)\n",
    "    data = data.lower()\n",
    "    data = expand_contractions(data)\n",
    "    data = re.sub('@[A-Za-z0-9_]+',' ', data)\n",
    "    data = re.sub('#[A-Za-z0-9_]+',' ', data)\n",
    "    data = re.sub('(http\\S+)', ' ', data)\n",
    "    data = re.sub('www.\\S+', ' ', data)\n",
    "    data = re.sub('[()!?]', ' ', data)\n",
    "    data = re.sub('\\[.*?\\]',' ', data)\n",
    "    data = re.sub('[^a-z0-9]',' ', data)\n",
    "    data = re.sub(' +',' ', data)\n",
    "    data = remove_stop_words(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "860b4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df.loc[:,['all_words','new_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e3303de",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['clean_all_words'] = clean_df['all_words'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac73536e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_words</th>\n",
       "      <th>new_category</th>\n",
       "      <th>clean_all_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>NEWS</td>\n",
       "      <td>4 million americans roll sleeves omicron targe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>NEWS</td>\n",
       "      <td>american airlines flyer charged banned life pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>23 funniest tweets cats dogs week sept 17 23 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING AND EDUCATION</td>\n",
       "      <td>funniest tweets parents week sept 17 23 accide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>NEWS</td>\n",
       "      <td>woman called cops black bird watcher loses law...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209522</th>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>rim ceo thorsten heins significant plans black...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209523</th>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>maria sharapova stunned victoria azarenka aust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209524</th>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>giants patriots jets colts among improbable su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209525</th>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>aldon smith arrested 49ers linebacker busted d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209526</th>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>dwight howard rips teammates magic loss hornet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209038 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                all_words  \\\n",
       "0       Over 4 Million Americans Roll Up Sleeves For O...   \n",
       "1       American Airlines Flyer Charged, Banned For Li...   \n",
       "2       23 Of The Funniest Tweets About Cats And Dogs ...   \n",
       "3       The Funniest Tweets From Parents This Week (Se...   \n",
       "4       Woman Who Called Cops On Black Bird-Watcher Lo...   \n",
       "...                                                   ...   \n",
       "209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...   \n",
       "209523  Maria Sharapova Stunned By Victoria Azarenka I...   \n",
       "209524  Giants Over Patriots, Jets Over Colts Among  M...   \n",
       "209525  Aldon Smith Arrested: 49ers Linebacker Busted ...   \n",
       "209526  Dwight Howard Rips Teammates After Magic Loss ...   \n",
       "\n",
       "                   new_category  \\\n",
       "0                          NEWS   \n",
       "1                          NEWS   \n",
       "2                 ENTERTAINMENT   \n",
       "3       PARENTING AND EDUCATION   \n",
       "4                          NEWS   \n",
       "...                         ...   \n",
       "209522               TECHNOLOGY   \n",
       "209523            ENTERTAINMENT   \n",
       "209524            ENTERTAINMENT   \n",
       "209525            ENTERTAINMENT   \n",
       "209526            ENTERTAINMENT   \n",
       "\n",
       "                                          clean_all_words  \n",
       "0       4 million americans roll sleeves omicron targe...  \n",
       "1       american airlines flyer charged banned life pu...  \n",
       "2       23 funniest tweets cats dogs week sept 17 23 d...  \n",
       "3       funniest tweets parents week sept 17 23 accide...  \n",
       "4       woman called cops black bird watcher loses law...  \n",
       "...                                                   ...  \n",
       "209522  rim ceo thorsten heins significant plans black...  \n",
       "209523  maria sharapova stunned victoria azarenka aust...  \n",
       "209524  giants patriots jets colts among improbable su...  \n",
       "209525  aldon smith arrested 49ers linebacker busted d...  \n",
       "209526  dwight howard rips teammates magic loss hornet...  \n",
       "\n",
       "[209038 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c74e3",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6371b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model=KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea6cccd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('scrumptious', 0.8770448565483093), ('tasty', 0.8730388879776001), ('delectable', 0.8363204598426819), ('yummy', 0.8119936585426331), ('flavorful', 0.7428319454193115), ('sinfully_delicious', 0.7334188222885132), ('scrumptious_desserts', 0.7285338640213013), ('delish', 0.7256091833114624), ('savory', 0.7186153531074524), ('decadent_dessert', 0.7114437818527222)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.most_similar('delicious'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98586048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65890074\n",
      "0.63959724\n",
      "-0.052412063\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.similarity('Scientist','Researcher'))\n",
    "print(w2v_model.similarity('Lake','River'))\n",
    "print(w2v_model.similarity('Lake','Iphone'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48c47a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = clean_df['clean_all_words'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ae6362c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model.get_vector('tiger'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8574a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.83593750e-02,  1.82617188e-01, -1.77734375e-01,  1.66015625e-01,\n",
       "        1.46484375e-01,  2.53906250e-02,  5.00488281e-02, -3.51562500e-02,\n",
       "        2.53906250e-01,  2.22778320e-03, -3.26156616e-04, -2.05078125e-01,\n",
       "       -2.98828125e-01, -3.71093750e-01, -4.45312500e-01, -2.08007812e-01,\n",
       "       -1.89453125e-01, -5.72204590e-04, -2.45117188e-01, -2.08984375e-01,\n",
       "        2.51953125e-01, -3.73046875e-01,  1.91406250e-01, -2.07519531e-02,\n",
       "       -2.96875000e-01,  1.24023438e-01, -4.60937500e-01,  1.42578125e-01,\n",
       "        7.14843750e-01,  1.18652344e-01, -1.47460938e-01, -1.15234375e-01,\n",
       "       -9.03320312e-02, -8.49609375e-02, -3.14453125e-01,  1.54296875e-01,\n",
       "       -1.97265625e-01,  2.89062500e-01,  3.26171875e-01,  2.79296875e-01,\n",
       "       -2.13623047e-02, -7.76367188e-02,  1.29882812e-01,  1.79687500e-01,\n",
       "        2.85156250e-01, -2.45117188e-01, -7.22656250e-02, -1.08398438e-01,\n",
       "        3.96484375e-01,  2.75390625e-01, -2.94921875e-01,  2.87109375e-01,\n",
       "       -9.33837891e-03, -2.14843750e-01,  1.03515625e-01, -1.32812500e-01,\n",
       "        1.90429688e-01, -2.53906250e-01,  3.82812500e-01,  3.58886719e-02,\n",
       "        1.00585938e-01,  1.04492188e-01,  1.65039062e-01, -2.19726562e-01,\n",
       "        1.37695312e-01, -1.88476562e-01,  7.03125000e-02, -8.98437500e-02,\n",
       "       -2.16796875e-01, -7.53784180e-03, -8.69140625e-02,  5.95703125e-02,\n",
       "        7.03125000e-02, -5.88378906e-02, -4.66308594e-02, -3.63769531e-02,\n",
       "        1.15234375e-01, -3.39843750e-01, -8.72802734e-03, -1.93023682e-03,\n",
       "       -1.87988281e-02, -1.90429688e-01,  1.64062500e-01,  2.53906250e-01,\n",
       "       -3.49609375e-01, -1.04003906e-01, -7.32421875e-02, -2.09960938e-01,\n",
       "       -7.86132812e-02, -1.17675781e-01, -4.15039062e-02,  4.33593750e-01,\n",
       "       -6.54296875e-02,  5.88378906e-02, -2.98828125e-01, -4.25781250e-01,\n",
       "        1.84570312e-01,  1.20605469e-01,  1.80664062e-01, -2.53906250e-01,\n",
       "       -7.66601562e-02, -1.54296875e-01, -2.57568359e-02, -1.66015625e-01,\n",
       "        2.27539062e-01, -2.94921875e-01, -9.66796875e-02, -1.21582031e-01,\n",
       "        1.14746094e-01, -1.35742188e-01, -5.19531250e-01,  8.39843750e-02,\n",
       "        2.95410156e-02,  2.89062500e-01, -1.96289062e-01, -8.64257812e-02,\n",
       "       -1.44531250e-01, -4.86328125e-01, -2.75390625e-01, -2.92968750e-02,\n",
       "       -1.94091797e-02,  1.94335938e-01, -3.65234375e-01, -1.27563477e-02,\n",
       "       -1.43554688e-01,  6.25000000e-02,  3.82812500e-01, -8.44726562e-02,\n",
       "        1.50390625e-01, -3.71093750e-01, -1.42578125e-01,  1.21582031e-01,\n",
       "       -3.24218750e-01,  1.49414062e-01, -2.26562500e-01,  1.87500000e-01,\n",
       "        9.17968750e-02,  2.38037109e-02,  9.08203125e-02,  5.93261719e-02,\n",
       "        1.87500000e-01, -3.08593750e-01, -7.42187500e-02,  6.64062500e-02,\n",
       "        4.80957031e-02,  3.04687500e-01, -1.74804688e-01,  2.83203125e-01,\n",
       "        1.50756836e-02, -1.04492188e-01,  4.64843750e-01,  1.53320312e-01,\n",
       "       -2.75390625e-01,  2.04101562e-01,  1.91406250e-01, -2.50000000e-01,\n",
       "        1.20849609e-02, -3.54003906e-02,  1.46484375e-01, -1.80664062e-01,\n",
       "        1.25000000e-01, -2.06054688e-01,  2.11914062e-01, -5.93261719e-02,\n",
       "        8.66699219e-03, -8.15429688e-02,  2.69531250e-01, -2.51953125e-01,\n",
       "       -2.72216797e-02,  1.25000000e-01, -9.27734375e-02, -7.17773438e-02,\n",
       "        4.44335938e-02,  1.29882812e-01,  7.03125000e-02, -8.34960938e-02,\n",
       "        3.71093750e-02,  9.47265625e-02, -2.00195312e-01, -3.26171875e-01,\n",
       "       -2.75390625e-01, -2.38281250e-01, -1.22558594e-01, -1.31835938e-01,\n",
       "        5.68847656e-02, -2.33398438e-01,  1.04370117e-02,  1.86523438e-01,\n",
       "        2.33398438e-01,  5.46875000e-02, -6.73828125e-02, -4.35546875e-01,\n",
       "       -2.59765625e-01,  1.79687500e-01,  1.07910156e-01,  4.15039062e-02,\n",
       "        1.95312500e-02, -2.61718750e-01, -1.46484375e-01,  5.98144531e-02,\n",
       "        1.27929688e-01, -1.46484375e-01,  4.48608398e-03, -1.48437500e-01,\n",
       "        1.14257812e-01,  2.33459473e-03,  3.53515625e-01, -2.27539062e-01,\n",
       "        1.12792969e-01, -4.10156250e-02, -5.31250000e-01, -7.27539062e-02,\n",
       "        1.37695312e-01, -6.17187500e-01, -1.21582031e-01,  2.94921875e-01,\n",
       "        3.80859375e-01, -3.88183594e-02,  6.00585938e-02,  2.35351562e-01,\n",
       "        1.32812500e-01,  2.85644531e-02, -2.63671875e-01, -1.38671875e-01,\n",
       "        1.61132812e-01, -1.07421875e-01, -1.05468750e-01,  1.17675781e-01,\n",
       "        3.08593750e-01, -3.66210938e-02,  8.59375000e-02, -1.49414062e-01,\n",
       "        1.63085938e-01,  1.89971924e-03, -1.30859375e-01, -1.34765625e-01,\n",
       "       -5.73730469e-02,  7.37304688e-02, -1.10839844e-01, -1.23046875e-01,\n",
       "        2.69531250e-01, -2.83203125e-01, -8.44726562e-02, -2.42187500e-01,\n",
       "        1.53320312e-01,  9.88769531e-03,  3.19824219e-02, -2.08007812e-01,\n",
       "        3.00781250e-01, -1.85546875e-02, -2.71484375e-01,  1.93359375e-01,\n",
       "       -9.86328125e-02,  1.25000000e-01, -1.64794922e-02,  6.25000000e-02,\n",
       "        8.48388672e-03, -1.80664062e-01, -2.13867188e-01, -1.66015625e-01,\n",
       "       -2.77343750e-01,  1.38671875e-01,  5.62500000e-01,  3.75976562e-02,\n",
       "        2.19726562e-01,  2.13867188e-01, -4.86328125e-01, -9.86328125e-02,\n",
       "       -3.12500000e-02, -1.98242188e-01,  3.03649902e-03,  4.44335938e-02,\n",
       "        4.02832031e-02,  3.51562500e-01,  2.50000000e-01,  1.00097656e-01,\n",
       "        1.93786621e-03,  5.37109375e-02, -2.04101562e-01,  5.09643555e-03,\n",
       "        2.63671875e-01, -8.88671875e-02, -2.05078125e-01, -1.07421875e-01,\n",
       "        1.27929688e-01, -9.08203125e-02, -1.06445312e-01,  1.34887695e-02,\n",
       "        3.12500000e-01, -2.31933594e-02, -1.05468750e-01, -5.05371094e-02,\n",
       "        1.46484375e-01, -2.62451172e-02,  9.03320312e-02,  3.95507812e-02,\n",
       "        2.94189453e-02,  1.90429688e-01, -1.02050781e-01,  1.72851562e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.get_vector('tiger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b55560e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(w2v_model.key_to_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57469568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'tiger' in vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e40630d",
   "metadata": {},
   "source": [
    "### Creating Average Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f48f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_w2v(sentence):\n",
    "    current_vect = np.zeros(300)\n",
    "    cnt_of_words = 0\n",
    "    for word in sentence.split():\n",
    "        if word in vocab:\n",
    "            vector = w2v_model.get_vector(word)\n",
    "            current_vect += vector\n",
    "            cnt_of_words += 1\n",
    "    current_vect /= cnt_of_words\n",
    "    return current_vect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f8d70e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['avg_w2v'] = clean_df['clean_all_words'].apply(get_avg_w2v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a358aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = clean_df['clean_all_words'].tolist()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a881f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = dict(zip(tfidf_vectorizer.get_feature_names(), tfidf_vectorizer.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2eac3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf_w2v(sentence):\n",
    "    current_vect = np.zeros(300)\n",
    "    sum_of_weights = 0\n",
    "    for word in sentence.split():\n",
    "        try:\n",
    "            vector = w2v_model.get_vector(word)\n",
    "            tf_idf = dic[word]\n",
    "            current_vect += (vector*tf_idf) \n",
    "            sum_of_weights += tf_idf\n",
    "        except:\n",
    "            continue\n",
    "    if sum_of_weights > 0:\n",
    "        return (current_vect/sum_of_weights)\n",
    "    else:\n",
    "        return np.zeros(300)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d14f40d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['tf_idf_w2v'] = clean_df['clean_all_words'].apply(get_tf_idf_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2365f3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209038, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6ed0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83375a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_array(array):\n",
    "    return np.any(np.isnan(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1404c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['bool_avg'] = clean_df['avg_w2v'].apply(check_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbba634d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_words</th>\n",
       "      <th>new_category</th>\n",
       "      <th>clean_all_words</th>\n",
       "      <th>avg_w2v</th>\n",
       "      <th>tf_idf_w2v</th>\n",
       "      <th>bool_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63714</th>\n",
       "      <td>\"ManScraping\"</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>manscraping</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66203</th>\n",
       "      <td>Wafflewich</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>wafflewich</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76593</th>\n",
       "      <td>The Opinionator</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>opinionator</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86508</th>\n",
       "      <td>Once.</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td></td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90944</th>\n",
       "      <td></td>\n",
       "      <td>POLITICS</td>\n",
       "      <td></td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96824</th>\n",
       "      <td>WHAAAAAAAT!?</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>whaaaaaaat</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98808</th>\n",
       "      <td>No, No, No!</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td></td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101055</th>\n",
       "      <td>WHO Are You Now ?</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td></td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104914</th>\n",
       "      <td>WHERE'S VLAD?</td>\n",
       "      <td>NEWS</td>\n",
       "      <td>vlad</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105315</th>\n",
       "      <td>#Anxiety</td>\n",
       "      <td>LIFESTYLE</td>\n",
       "      <td></td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110960</th>\n",
       "      <td>WTFark, 2014!</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>wtfark 2014</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113992</th>\n",
       "      <td>Ένας νεκρός σε συγκρούσεις μεταξύ διαδηλωτών κ...</td>\n",
       "      <td>ENVIRONMENT</td>\n",
       "      <td></td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114414</th>\n",
       "      <td>As We Are</td>\n",
       "      <td>LIFESTYLE</td>\n",
       "      <td></td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115562</th>\n",
       "      <td>The 80/20... What?</td>\n",
       "      <td>LIFESTYLE</td>\n",
       "      <td>80 20</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120484</th>\n",
       "      <td>Karoline Hjorth and Riitta Ikonen on the Image...</td>\n",
       "      <td>TRAVEL AND ARTS</td>\n",
       "      <td>karoline hjorth riitta ikonen imageblog</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125181</th>\n",
       "      <td>50/50</td>\n",
       "      <td>MISCELLANEOUS</td>\n",
       "      <td>50 50</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127231</th>\n",
       "      <td>Over</td>\n",
       "      <td>MISCELLANEOUS</td>\n",
       "      <td></td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128827</th>\n",
       "      <td>They're Against It. (They're Against Him.)</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td></td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129600</th>\n",
       "      <td>Because I Can</td>\n",
       "      <td>LIFESTYLE</td>\n",
       "      <td></td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129862</th>\n",
       "      <td>Attendez</td>\n",
       "      <td>TRAVEL AND ARTS</td>\n",
       "      <td>attendez</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                all_words     new_category  \\\n",
       "63714                                      \"ManScraping\"     ENTERTAINMENT   \n",
       "66203                                         Wafflewich              FOOD   \n",
       "76593                                    The Opinionator     ENTERTAINMENT   \n",
       "86508                                              Once.     ENTERTAINMENT   \n",
       "90944                                                             POLITICS   \n",
       "96824                                       WHAAAAAAAT!?     ENTERTAINMENT   \n",
       "98808                                        No, No, No!     ENTERTAINMENT   \n",
       "101055                                 WHO Are You Now ?     ENTERTAINMENT   \n",
       "104914                                     WHERE'S VLAD?              NEWS   \n",
       "105315                                          #Anxiety         LIFESTYLE   \n",
       "110960                                     WTFark, 2014!     ENTERTAINMENT   \n",
       "113992  Ένας νεκρός σε συγκρούσεις μεταξύ διαδηλωτών κ...      ENVIRONMENT   \n",
       "114414                                         As We Are         LIFESTYLE   \n",
       "115562                                The 80/20... What?         LIFESTYLE   \n",
       "120484  Karoline Hjorth and Riitta Ikonen on the Image...  TRAVEL AND ARTS   \n",
       "125181                                             50/50     MISCELLANEOUS   \n",
       "127231                                              Over     MISCELLANEOUS   \n",
       "128827        They're Against It. (They're Against Him.)          POLITICS   \n",
       "129600                                     Because I Can         LIFESTYLE   \n",
       "129862                                          Attendez   TRAVEL AND ARTS   \n",
       "\n",
       "                                clean_all_words  \\\n",
       "63714                               manscraping   \n",
       "66203                                wafflewich   \n",
       "76593                               opinionator   \n",
       "86508                                             \n",
       "90944                                             \n",
       "96824                                whaaaaaaat   \n",
       "98808                                             \n",
       "101055                                            \n",
       "104914                                     vlad   \n",
       "105315                                            \n",
       "110960                              wtfark 2014   \n",
       "113992                                            \n",
       "114414                                            \n",
       "115562                                    80 20   \n",
       "120484  karoline hjorth riitta ikonen imageblog   \n",
       "125181                                    50 50   \n",
       "127231                                            \n",
       "128827                                            \n",
       "129600                                            \n",
       "129862                                 attendez   \n",
       "\n",
       "                                                  avg_w2v  \\\n",
       "63714   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "66203   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "76593   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "86508   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "90944   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "96824   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "98808   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "101055  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "104914  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "105315  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "110960  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "113992  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "114414  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "115562  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "120484  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "125181  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "127231  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "128827  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "129600  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "129862  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "\n",
       "                                               tf_idf_w2v  bool_avg  \n",
       "63714   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "66203   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "76593   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "86508   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "90944   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "96824   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "98808   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "101055  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "104914  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "105315  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "110960  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "113992  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "114414  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "115562  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "120484  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "125181  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "127231  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "128827  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "129600  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  \n",
       "129862  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      True  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.loc[clean_df.bool_avg, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5c36c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "clean_df['new_category'] = label.fit_transform(clean_df['new_category'])\n",
    "clean_df = clean_df.loc[~clean_df.bool_avg,['new_category','avg_w2v','tf_idf_w2v']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9de4b1",
   "metadata": {},
   "source": [
    "#  Avg w2v Split and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b232aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_df['avg_w2v'].to_list()\n",
    "y = clean_df['new_category'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa9b3471",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15460\\1175925103.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "x_train,x_test, y_train,y_test = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b7c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(x_train,y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print('accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ebdd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd =  SGDClassifier(loss='hinge', penalty='l2')\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred = sgd.predict(x_test)\n",
    "print('accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78cc344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "p = Pipeline([('Normalizing',MinMaxScaler()),('MultinomialNB',MultinomialNB())])\n",
    "p.fit(x_train,y_train) \n",
    "print('accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca049df",
   "metadata": {},
   "source": [
    "# Tf - Idf W2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_df['tf_idf_w2v'].to_list()\n",
    "y = clean_df['new_category'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76164e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train,y_test = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92552d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(x_train,y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print('accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9876553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd =  SGDClassifier(loss='hinge', penalty='l2')\n",
    "sgd.fit(x_train,y_train)\n",
    "y_pred = sgd.predict(x_test)\n",
    "print('accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c79d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "p = Pipeline([('Normalizing',MinMaxScaler()),('MultinomialNB',MultinomialNB())])\n",
    "p.fit(x_train,y_train) \n",
    "print('accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb73863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
